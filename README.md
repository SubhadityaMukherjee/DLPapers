# DEEP LEARNING PAPERS

- This repository contains implementations of various Deep learning papers
- Models have been trained for a little time and will give better results if trained more. The focus was more on understanding rather than results
- An index of papers implemented along with the citations and URLs are as follows
> Note: Code in PyTorch

## INDEX

**[1]** Alex Net
- Krizhevsky, Alex, Ilya Sutskever, and Geoffrey E. Hinton. "Imagenet classification with deep convolutional neural networks." Advances in neural information processing systems. 2012
[Paper](http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf)

**[2]** VGG Net
 - Simonyan, Karen, and Andrew Zisserman. "Very deep convolutional networks for large-scale image recognition." arXiv preprint arXiv:1409.1556 (2014).
 [Paper](https://arxiv.org/pdf/1409.1556.pdf)

**[3]** GoogLe Net
 - Szegedy, Christian, et al. "Going deeper with convolutions." Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2015.
 [Paper](http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Szegedy_Going_Deeper_With_2015_CVPR_paper.pdf)

**[4]** Dropout (Just notes)
- Srivastava, Nitish, et al. "Dropout: a simple way to prevent neural networks from overfitting." Journal of Machine Learning Research 15.1 (2014): 1929-1958.
[Paper](http://jmlr.org/papers/volume15/srivastava14a/srivastava14a.pdf)

**[5]** Mobile Net
- MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications (2017), Andrew G. Howard et al.
[Paper](https://arxiv.org/pdf/1704.04861.pdf)

**[6]** Inceptionism
- Google Deep Dream [Link](https://ai.googleblog.com/2015/06/inceptionism-going-deeper-into-neural.html)

**[7]** DC GAN
- Radford, A., Metz, L., & Chintala, S. (2015). Unsupervised representation learning with deep convolutional generative adversarial networks. arXiv preprint arXiv:1511.06434.
[Paper](https://arxiv.org/pdf/1511.06434.pdf%C3)

**[8]** Spatial Transformer Networks
- Jaderberg, M., Simonyan, K., & Zisserman, A. (2015). Spatial transformer networks. In Advances in neural information processing systems (pp. 2017-2025).
[Paper](http://papers.nips.cc/paper/5854-spatial-transformer-networks.pdf)

**[9]** Squeeze Net
- SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and< 1MB model size (2016), F. Iandola et al.
[Paper](http://arxiv.org/pdf/1602.07360)

**[10]** VAE (Auto-Encoding Variational Bayes)
- Kingma, D. P., & Welling, M. (2013). Auto-encoding variational bayes. arXiv preprint arXiv:1312.6114.
[Paper](https://arxiv.org/pdf/1312.6114.pdf?source=post_page---------------------------)

**[11]** SRCNN
- Dong, C., Loy, C. C., He, K., & Tang, X. (2014, September). Learning a deep convolutional network for image super-resolution. In European conference on computer vision (pp. 184-199). Springer, Cham.
[Paper](https://www.researchgate.net/profile/Chen_Change_Loy/publication/264552416_Lecture_Notes_in_Computer_Science/links/53e583e50cf25d674e9c280e.pdf)

**[12]** WGAN
- Arjovsky, M., Chintala, S., & Bottou, L. (2017). Wasserstein gan. arXiv preprint arXiv:1701.07875.
[Paper](https://arxiv.org/pdf/1701.07875.pdf%20http://arxiv.org/abs/1701.07875)

**[13]** One cycle (Just notes)
- Smith, L. N. (2017, March). Cyclical learning rates for training neural networks. In 2017 IEEE Winter Conference on Applications of Computer Vision (WACV) (pp. 464-472). IEEE.
[Paper](https://arxiv.org/pdf/1506.01186.pdf%EF%BC%89%EF%BC%8C%E8%BF%99%E7%A7%8D%E5%A5%87%E6%8A%80%E6%B7%AB%E5%B7%A7%E5%B0%86%E8%8E%B7%E5%BE%97%E6%9B%B4%E9%AB%98%E7%9A%84%E6%B5%8B%E8%AF%95%E5%87%86%E7%A1%AE%E7%8E%87%EF%BC%8C%E4%BD%86%E6%98%AF%E4%BD%A0%E7%9C%8B%E8%BF%99%E4%B8%AAlearning)

**[14]** A disciplined approach to neural network hyper-parameters (Just notes)
- Smith, L. N. (2018). A disciplined approach to neural network hyper-parameters: Part 1--learning rate, batch size, momentum, and weight decay. arXiv preprint arXiv:1803.09820.
[Paper](https://arxiv.org/pdf/1803.09820)

**[15]** Class Imbalance Problem (Just notes)
- Buda, M., Maki, A., & Mazurowski, M. A. (2018). A systematic study of the class imbalance problem in convolutional neural networks. Neural Networks, 106, 249-259. [Paper](https://arxiv.org/pdf/1710.05381)

**[16]** Perceptual Loss (For super resolution)
- Johnson, J., Alahi, A., & Fei-Fei, L. (2016, October). Perceptual losses for real-time style transfer and super-resolution. In European conference on computer vision (pp. 694-711). Springer, Cham. [Paper](https://arxiv.org/pdf/1603.08155.pdf%7C)
